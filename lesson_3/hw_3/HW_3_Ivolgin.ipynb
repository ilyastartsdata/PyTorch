{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW 3"
      ],
      "metadata": {
        "id": "_UjS9e4YY-rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Создать Dataset для загрузки данных\n",
        "2. Обернуть его в Dataloader\n",
        "3. Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
        "4. Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели\n",
        "\n",
        "*train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25"
      ],
      "metadata": {
        "id": "OhjtQ0g0bX_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Nxc9cd0cbhrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка библиотек\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import datetime as dt\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "8HhYipWmbMul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "california_housing = fetch_california_housing(as_frame = True)"
      ],
      "metadata": {
        "id": "-VcI4UnWZVm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "f8lQVuI4e2Jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.RandomState(0)\n",
        "indices = rng.choice(np.arange(california_housing.frame.shape[0]), size = 500,\n",
        "                     replace = False)\n",
        "columns_drop = ['Longitude', 'Latitude']\n",
        "df = california_housing.frame.iloc[indices].drop(columns = columns_drop)\n",
        "train_y = df['MedHouseVal'].values\n",
        "df = df.drop(['MedHouseVal'], axis = 1)"
      ],
      "metadata": {
        "id": "o9lji_qTe3HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "hrebYtGgfosZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "rkCUtzPCgb3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, train_y, test_size = 0.25, random_state = 13)"
      ],
      "metadata": {
        "id": "YqXm3HtghzJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "yBquMFFPj7U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "  \n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.Tensor(X)\n",
        "        self.y = torch.from_numpy(y).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        return (self.X[index], self.y[index])\n",
        "\n",
        "class Perceptron(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, activation = \"relu\"):\n",
        "        super(Perceptron, self).__init__()\n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "        self.activation = activation\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        if self.activation == \"relu\":\n",
        "            return torch.relu(x)\n",
        "        if self.activation == \"sigmoid\":\n",
        "            return torch.sigmoid(x)\n",
        "        raise RuntimeError"
      ],
      "metadata": {
        "id": "XolqcMfXjq4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm1d(input_dim)\n",
        "        self.fc1 = Perceptron(input_dim, hidden_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.dp = nn.Dropout(0.25)\n",
        "        self.fc2 = Perceptron(hidden_dim, 1, \"sigmoid\")\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.bn1(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dp(x)\n",
        "        x = self.fc2(x)\n",
        "        return x.view(-1)"
      ],
      "metadata": {
        "id": "61_4mBZ3kPvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = FeedForward(len(X_train[0]), 50)"
      ],
      "metadata": {
        "id": "B45fBDX-lBlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        dataset: пользовательский класс, предобрабатывающий данные\n",
        "        loss_f: функция потерь\n",
        "        learning_rate: величина градиентного шага\n",
        "        epoch_amount: общее количество эпох\n",
        "        batch_size: размер одного бача\n",
        "        max_batches_per_epoch: максимальное количество бачей, \n",
        "                               подаваемых в модель в одну эпоху\n",
        "        device: устройство для вычислений\n",
        "        early_stopping: количество эпох без улучшений до остановки обучения\n",
        "        optim: оптимизатор\n",
        "        scheduler: регулятор градиентного шага\n",
        "        permutate: перемешивание тренировочной выборки перед обучением\n",
        "\n",
        "    Attributes:\n",
        "        start_model: необученная модель\n",
        "        best_model: модель, после обучения\n",
        "        train_loss: средние значения функции потерь на тренировочных \n",
        "                    данных в каждой эпохе\n",
        "        val_loss: средние значения функции потерь на валидационных \n",
        "                  данных в каждой эпохе\n",
        "\n",
        "    Methods:\n",
        "        fit: обучение модели\n",
        "        predict: возвращает предсказание обученной моделью\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self,  dataset, net, loss_f, learning_rate=1e-3, \n",
        "                epoch_amount=10, batch_size=12, \n",
        "                max_batches_per_epoch=None,\n",
        "                device='cpu', early_stopping=10, \n",
        "                optim=torch.optim.Adam, \n",
        "                scheduler=None, permutate=True):\n",
        "        \n",
        "        self.loss_f = loss_f\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epoch_amount = epoch_amount\n",
        "        self.batch_size = batch_size\n",
        "        self.max_batches_per_epoch = max_batches_per_epoch\n",
        "        self.device = device\n",
        "        self.early_stopping = early_stopping\n",
        "        self.optim = optim\n",
        "        self.scheduler = scheduler\n",
        "        self.permutate = permutate\n",
        "        self.dataset = dataset\n",
        "        self.start_model = net\n",
        "        self.best_model = net\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.best_model(X)\n",
        "\n",
        "    def fit(self, X_train, X_test, y_train, y_test):\n",
        "\n",
        "        Net = self.start_model\n",
        "            \n",
        "        device = torch.device(self.device)\n",
        "\n",
        "        Net.to(self.device)\n",
        "\n",
        "        optimizer = self.optim(Net.parameters(), lr=self.learning_rate)\n",
        "        \n",
        "        if self.scheduler is not None:\n",
        "            scheduler = self.scheduler(optimizer)\n",
        "\n",
        "        train = self.dataset(X_train, y_train)\n",
        "        val = self.dataset(X_test, y_test)  \n",
        "\n",
        "        train = DataLoader(train, batch_size=self.batch_size, shuffle=self.permutate) \n",
        "        val = DataLoader(val, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        best_val_loss = float('inf') # Лучшее значение функции потерь на валидационной выборке\n",
        "        best_ep = 0                  # Эпоха, на которой достигалось лучшее \n",
        "                                     # значение функции потерь на валидационной выборке\n",
        "\n",
        "        for epoch in range(self.epoch_amount): \n",
        "            start = dt.datetime.now()\n",
        "            print(f'Эпоха: {epoch}', end=' ')\n",
        "            Net.train()\n",
        "            mean_loss = 0\n",
        "            batch_n = 0\n",
        "\n",
        "            for batch_X, target in train:\n",
        "                if self.max_batches_per_epoch is not None:\n",
        "                    if batch_n >= self.max_batches_per_epoch:\n",
        "                        break\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                batch_X = batch_X.to(self.device)\n",
        "                target = target.to(self.device)\n",
        "\n",
        "                predicted_values = Net(batch_X)\n",
        "                loss = self.loss_f(predicted_values, target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                mean_loss += float(loss)\n",
        "                batch_n += 1\n",
        "        \n",
        "            mean_loss /= batch_n\n",
        "            self.train_loss.append(mean_loss)\n",
        "            print(f'Loss_train: {mean_loss}, {dt.datetime.now() - start} сек')\n",
        "\n",
        "            Net.eval()\n",
        "            mean_loss = 0\n",
        "            batch_n = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch_X, target in val:\n",
        "                    if self.max_batches_per_epoch is not None:\n",
        "                        if batch_n >= self.max_batches_per_epoch:\n",
        "                            break\n",
        "                batch_X = batch_X.to(self.device)\n",
        "                target = target.to(self.device)\n",
        "\n",
        "                predicted_values = Net(batch_X)\n",
        "                loss = self.loss_f(predicted_values, target)\n",
        "\n",
        "                mean_loss += float(loss)\n",
        "                batch_n += 1\n",
        "        \n",
        "            mean_loss /= batch_n\n",
        "            self.val_loss.append(mean_loss)\n",
        "            print(f'Loss_val: {mean_loss}')\n",
        "\n",
        "            if mean_loss < best_val_loss:\n",
        "                self.best_model = Net\n",
        "                best_val_loss = mean_loss\n",
        "                best_ep = epoch\n",
        "            elif epoch - best_ep > self.early_stopping:\n",
        "                print(f'{self.early_stopping} без улучшений. Прекращаем обучение...')\n",
        "                break\n",
        "            if self.scheduler is not None:\n",
        "                scheduler.step()\n",
        "            print()"
      ],
      "metadata": {
        "id": "Lo7fkPK-kHSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        \n",
        "    def forward(self,yhat,y):\n",
        "        return torch.sqrt(self.mse(yhat,y))"
      ],
      "metadata": {
        "id": "wgHsE32nlVwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'dataset': MyDataset,\n",
        "    'net': net,\n",
        "    'batch_size': 1000,\n",
        "    'epoch_amount': 100, \n",
        "    'learning_rate': 1e-2,\n",
        "    'early_stopping': 10,\n",
        "    'loss_f': RMSELoss(),\n",
        "    'optim': torch.optim.SGD,\n",
        "}"
      ],
      "metadata": {
        "id": "q-jNcDMPlPx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = Trainer(**params)\n",
        "clf.fit(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "LDFJd8gAlP8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1 = FeedForward(len(X_train[0]), 50)\n",
        "\n",
        "params = {\n",
        "    'dataset': MyDataset,\n",
        "    'net': net1,\n",
        "    'batch_size': 1000,\n",
        "    'epoch_amount': 100, \n",
        "    'learning_rate': 1e-2,\n",
        "    'early_stopping': 10,\n",
        "    'loss_f': RMSELoss(),\n",
        "    'optim': torch.optim.Adam,\n",
        "}\n",
        "\n",
        "clf1 = Trainer(**params)\n",
        "clf1.fit(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "gK2pAUaok8CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = FeedForward(len(X_train[0]), 50)\n",
        "\n",
        "params = {\n",
        "    'dataset': MyDataset,\n",
        "    'net': net2,\n",
        "    'batch_size': 1000,\n",
        "    'epoch_amount': 100, \n",
        "    'learning_rate': 1e-2,\n",
        "    'early_stopping': 10,\n",
        "    'loss_f': RMSELoss(),\n",
        "    'optim': torch.optim.RMSprop,\n",
        "}\n",
        "\n",
        "clf2 = Trainer(**params)\n",
        "clf2.fit(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "t9sOWUrUll91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:** операторы показывают примерно равную эффективность"
      ],
      "metadata": {
        "id": "lxkwJucZlzqD"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "HW_3_Ivolgin.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}