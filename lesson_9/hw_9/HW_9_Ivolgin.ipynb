{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#HW 9"
      ],
      "metadata": {
        "id": "cbe9HL1VJzhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание\n",
        "\n",
        "1. Возьмите готовую модель из https://huggingface.co/models для классификации сентимента текста.\n",
        "2. Сделайте предсказания на всем df_val. Посчитайте метрику качества.\n",
        "3. Дообучите эту модель на df_train. Посчитайте метрику качества на df_val.\n",
        "\n",
        "Данные на google drive: https://drive.google.com/file/d/1Mev_EEput0LlBj8MDHIJkBtahlJ6J901"
      ],
      "metadata": {
        "id": "k5QxjZh1v93V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "WRdcncHAJ_Wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "tK-x0IP-KGcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "YCv1bpnXLXlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка библиотек\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import torchmetrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from transformers import pipeline\n",
        "from transformers import BertTokenizer, BertForSequenceClassification"
      ],
      "metadata": {
        "id": "BJ0nfgg7J_1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "TWn6xYsTLmI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка модели\n",
        "\n",
        "model_bert = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
        "print(model_bert)\n",
        "print(\"Parameters full train:\", sum([param.nelement() for param in model_bert.parameters()]))"
      ],
      "metadata": {
        "id": "Yjew7mmbK2UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример классификации\n",
        "\n",
        "sentiment = pipeline(\"text-classification\", model='SkolkovoInstitute/russian_toxicity_classifier')\n",
        "sentiment(\"Этот ресторан отличный\")"
      ],
      "metadata": {
        "id": "QiLAIhGpLrso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример токенизации\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
        "\n",
        "example_text = 'Пример текста для токенизации'\n",
        "\n",
        "bert_input = tokenizer(example_text, padding='max_length', max_length=10, \n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "print(bert_input['input_ids'])\n",
        "print(bert_input['attention_mask'])"
      ],
      "metadata": {
        "id": "3ffuRUHvLzZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tokenizer.decode(bert_input.input_ids[0])\n",
        "\n",
        "print(example_text)"
      ],
      "metadata": {
        "id": "PcvnkKNQL3mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "meyuk4t8L_-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_csv = '/content/drive/My Drive/data/train.csv'\n",
        "val_csv = '/content/drive/My Drive/data/val.csv'\n",
        "\n",
        "df_train = pd.read_csv(train_csv)\n",
        "df_val = pd.read_csv(val_csv)"
      ],
      "metadata": {
        "id": "zf2OEFaZL-2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "RHJjW-K5N1j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val.head()"
      ],
      "metadata": {
        "id": "QYPwfguwOCCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = pipeline(\"text-classification\", model='SkolkovoInstitute/russian_toxicity_classifier')\n",
        "\n",
        "idx = 0\n",
        "print(df_train.iloc[idx]['text'])\n",
        "print('label is', df_train.iloc[idx]['class'])\n",
        "print('label by model is', sentiment(df_train.iloc[idx]['text'])[0]['label'], 'with score', sentiment(df_train.iloc[idx]['text'])[0]['score'])"
      ],
      "metadata": {
        "id": "xgsUNwKkODSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "j00jk3fZOH2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим датасет и даталоадер\n",
        "\n",
        "# Class TwitterDataset\n",
        "\n",
        "class TwitterDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, txts, labels):\n",
        "        self._labels = labels\n",
        "        \n",
        "        self.tokenizer = BertTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
        "        #для каждого text возвращает батч с полями:\n",
        "               #'inputs_ids' -- тензор размера (B,1,max_len) из id токенов\n",
        "               #'token_type_ids' -- тензор размера (B,1,max_len) из id типов токенов\n",
        "               #'attention_mask' -- тензор размера (B,1,max_len) из индексов, указывающих, на какие токеты модель должна обратить внима\n",
        "        self._txts = [self.tokenizer(text, padding='max_length', max_length=10,\n",
        "                                     truncation=True, return_tensors=\"pt\")\n",
        "                      for text in txts]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self._txts)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self._txts[index], self._labels[index]"
      ],
      "metadata": {
        "id": "rx5T855aOFcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df_train['class'].values\n",
        "y_val = df_val['class'].values\n",
        "\n",
        "train_dataset = TwitterDataset(df_train['text'], y_train)\n",
        "valid_dataset = TwitterDataset(df_val['text'], y_val)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                          batch_size=64,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                          batch_size=64,\n",
        "                          shuffle=False,\n",
        "                          num_workers=0)"
      ],
      "metadata": {
        "id": "RSYkasUXOR9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for txt, lbl in train_loader:\n",
        "    print(txt.keys()) #словарь с ключами'input_ids', 'token_type_ids', 'attention_mask'\n",
        "    print(txt['input_ids'].shape) #тензор размера (B,1,max_len) из id токенов\n",
        "    print(txt['attention_mask'].shape) #тензор размера (B,1,max_len) из индексов, указывающих, на какие токеты модель должна обратить внимание\n",
        "    break"
      ],
      "metadata": {
        "id": "KcZhtupVOT75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "MZnLrv6hOWBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель на val\n",
        "\n",
        "# f1 score\n",
        "\n",
        "model_bert = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
        "\n",
        "valid_f1 = torchmetrics.F1Score()\n",
        "\n",
        "for val_input, val_label in valid_loader:\n",
        "    val_label = val_label\n",
        "    mask = val_input['attention_mask'] \n",
        "    input_id = val_input['input_ids'].squeeze(1)\n",
        "    \n",
        "    output = model_bert(input_id, mask)[0]\n",
        "    \n",
        "    valid_f1(output, val_label)\n",
        "    \n",
        "print(f'Val f1_score: {valid_f1.compute().item():.3f}')"
      ],
      "metadata": {
        "id": "_GMjEGUIOVfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "42uEX0WKOgu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Дообучение и новые метрики\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
        "print(model)\n",
        "print(\"Parameters full train:\", sum([param.nelement() for param in model.parameters()]))\n",
        "print(\"Parameters transfer learning:\", sum([param.nelement() for param in model.classifier.parameters()]))"
      ],
      "metadata": {
        "id": "f7ejwCBLOfsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Компиляция и обучение последнего слоя\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.classifier.parameters(), lr=0.001) "
      ],
      "metadata": {
        "id": "jrZ72i6oPMPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчет метрик\n",
        "\n",
        "train_f1 = torchmetrics.F1Score()\n",
        "valid_f1 = torchmetrics.F1Score()\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss_train = 0.0\n",
        "    for train_input, train_label in tqdm(train_loader):\n",
        "        mask = train_input['attention_mask']\n",
        "        input_id = train_input['input_ids'].squeeze(1)\n",
        "        train_label = train_label\n",
        "\n",
        "        output = model(input_id, mask)[0]\n",
        "                \n",
        "        batch_loss = criterion(output, train_label)\n",
        "        total_loss_train += batch_loss.item()\n",
        "                \n",
        "        train_f1(output, train_label)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "            \n",
        "    model.eval()\n",
        "    total_loss_val = 0.0\n",
        "    for val_input, val_label in valid_loader:\n",
        "        val_label = val_label\n",
        "        mask = val_input['attention_mask']\n",
        "        input_id = val_input['input_ids'].squeeze(1)\n",
        "\n",
        "        output = model(input_id, mask)[0]\n",
        "\n",
        "        batch_loss = criterion(output, val_label)\n",
        "        total_loss_val += batch_loss.item()\n",
        "                    \n",
        "        valid_f1(output, val_label)\n",
        "            \n",
        "    print(\n",
        "        f'Epochs: {epoch + 1} | Train Loss: {total_loss_train / len(train_dataset): .3f} \\\n",
        "        | Train f1: {train_f1.compute().item(): .3f} \\\n",
        "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
        "        | Val f1: {valid_f1.compute().item(): .3f}')\n",
        "    train_f1.reset()\n",
        "    valid_f1.reset()"
      ],
      "metadata": {
        "id": "AIZXSGPtPSlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f1\n",
        "\n",
        "valid_f1 = torchmetrics.F1Score()\n",
        "model.eval()\n",
        "\n",
        "for val_input, val_label in valid_loader:\n",
        "    val_label = val_label\n",
        "    mask = val_input['attention_mask'] \n",
        "    input_id = val_input['input_ids'].squeeze(1)\n",
        "    \n",
        "    output = model(input_id, mask)[0]\n",
        "    \n",
        "    valid_f1(output, val_label)\n",
        "    \n",
        "print(f'Val f1_score: {valid_f1.compute().item():.3f}')"
      ],
      "metadata": {
        "id": "Y4pTPfxHPXme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ZSddnwLIPep2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавление sigm\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.bert = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        pooled_output = self.bert(input_ids=x, attention_mask=mask,return_dict=False)[0]  #(B, 2)\n",
        "        final_layer = self.sigm(pooled_output)\n",
        "        return final_layer"
      ],
      "metadata": {
        "id": "QqqigRgRPbMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sigm = BertClassifier()\n",
        "print(model_sigm)\n",
        "print(\"Parameters full train:\", sum([param.nelement() for param in model_sigm.parameters()]))\n",
        "print(\"Parameters transfer learning:\", sum([param.nelement() for param in model_sigm.bert.classifier.parameters()]))"
      ],
      "metadata": {
        "id": "SJ1XO-M2PlTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Компиляция и дообучение\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = Adam(model_sigm.bert.classifier.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "QRqs4-whPouL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f1 = torchmetrics.F1Score()\n",
        "valid_f1 = torchmetrics.F1Score()\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model_sigm.train()\n",
        "    total_loss_train = 0.0\n",
        "    for train_input, train_label in tqdm(train_loader):\n",
        "        mask = train_input['attention_mask']\n",
        "        input_id = train_input['input_ids'].squeeze(1)\n",
        "        train_label = train_label\n",
        "\n",
        "        output = model_sigm(input_id, mask)\n",
        "                \n",
        "        batch_loss = criterion(output, train_label)\n",
        "        total_loss_train += batch_loss.item()\n",
        "                \n",
        "        train_f1(output, train_label)\n",
        "        \n",
        "        model_sigm.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "            \n",
        "    model_sigm.eval()\n",
        "    total_loss_val = 0.0\n",
        "    for val_input, val_label in valid_loader:\n",
        "        val_label = val_label\n",
        "        mask = val_input['attention_mask']\n",
        "        input_id = val_input['input_ids'].squeeze(1)\n",
        "\n",
        "        output = model_sigm(input_id, mask)\n",
        "\n",
        "        batch_loss = criterion(output, val_label)\n",
        "        total_loss_val += batch_loss.item()\n",
        "                    \n",
        "        valid_f1(output, val_label)\n",
        "            \n",
        "    print(\n",
        "        f'Epochs: {epoch + 1} | Train Loss: {total_loss_train / len(train_dataset): .3f} \\\n",
        "        | Train f1: {train_f1.compute().item(): .3f} \\\n",
        "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
        "        | Val f1: {valid_f1.compute().item(): .3f}')\n",
        "    train_f1.reset()\n",
        "    valid_f1.reset()"
      ],
      "metadata": {
        "id": "LUQdb5qPPxfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Метрика дообученной модели на валидационном датасете\n",
        "\n",
        "valid_f1 = torchmetrics.F1Score()\n",
        "model_sigm.eval()\n",
        "\n",
        "for val_input, val_label in valid_loader:\n",
        "    val_label = val_label\n",
        "    mask = val_input['attention_mask'] \n",
        "    input_id = val_input['input_ids'].squeeze(1)\n",
        "    \n",
        "    output = model_sigm(input_id, mask)\n",
        "    \n",
        "    valid_f1(output, val_label)\n",
        "    \n",
        "print(f'Val f1_score: {valid_f1.compute().item():.3f}')"
      ],
      "metadata": {
        "id": "By_1u2riP0gJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "HW_9_Ivolgin.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}